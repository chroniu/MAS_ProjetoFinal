{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, datetime\n",
    "import paramiko\n",
    "import csv\n",
    "from datetime import timedelta \n",
    "import mas_utils as utils\n",
    "import configs\n",
    "\n",
    "class InputError(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processa os arquivos e os transforma em .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATTERN_01 = 'procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----'\n",
    "PATTERN_02 = 'r  b   swpd  livre buffer  cache   si   so    bi    bo   in   cs us sy id wa st'\n",
    "\n",
    "def process_set(data, date_start, date_end, dt=None):\n",
    "        \n",
    "    if(dt is None):\n",
    "        dt = (date_end - date_start).total_seconds() / len(data)\n",
    "        delta = datetime.timedelta(seconds=dt)\n",
    "\n",
    "    date = date_start\n",
    "    result = []\n",
    "    for row in data:\n",
    "        #pdb.set_trace()\n",
    "        result.append([date]+row)\n",
    "        date += dt\n",
    "    return result\n",
    "    \n",
    "def process_file_data(data, start_index, dt=None):\n",
    "    server_name = None\n",
    "    processed_data = []\n",
    "    temp_process = None\n",
    "    actual_date = None\n",
    "    index = start_index\n",
    "    date_diff = None\n",
    "    header = None\n",
    "    while(index < len(data)):\n",
    "        if(data[index].strip().lower().startswith('procs')):# == PATTERN_01):\n",
    "            index += 1\n",
    "        elif(data[index].strip().lower().split()[0:2] == ['r', 'b']):#melhorar isso\n",
    "            header = data[index].strip().lower()\n",
    "            index += 1\n",
    "        elif(len(data[index].split()) >= 15): # para considerar os diferentes tipos  \n",
    "            d = data[index].split()\n",
    "            temp_process.append(d)\n",
    "            index += 1\n",
    "        elif(len(data[index].split()) == 3):\n",
    "            # verificar parada e break\n",
    "            name, date, d_time = data[index].split()\n",
    "            \n",
    "            date = datetime.datetime.strptime('{} {}'.format(date, d_time), \n",
    "                           \"%Y-%m-%d %H:%M:%S\")\n",
    "            if(server_name == None):\n",
    "                server_name = name.strip().lower()\n",
    "            elif(server_name != name.strip().lower()):\n",
    "                raise InputError('{} not equal to {}'.format(name, server_name))\n",
    "                return None\n",
    "            \n",
    "            if(temp_process is not None):\n",
    "                processed_data += process_set(temp_process, actual_date, date, dt)\n",
    "                date_diff = date - actual_date\n",
    "                temp_process = []\n",
    "            else:\n",
    "                temp_process = []\n",
    "            actual_date = date\n",
    "\n",
    "            index +=1\n",
    "        else:\n",
    "            raise InputError('error|{}|line {}'.format(data[index], index))\n",
    "            return None\n",
    "    \n",
    "    if(temp_process is not None):\n",
    "                processed_data += process_set(temp_process, actual_date, actual_date + date_diff, dt)\n",
    "    return processed_data, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_processed_file(data):\n",
    "    init = data[0][0]\n",
    "    end  = data[-1][0]\n",
    "    # deve ser alterada caso a periodo de amostragem seja diferente de 15\n",
    "    if(init.hour == 0 and init.minute == 0 and init.second >= 1 and \n",
    "        end.hour == 23 and end.minute == 59 and end.second >= 46):\n",
    "        # deve ser alterada caso a periodo de amostragem seja diferente de 15\n",
    "        expected = int(60*60*24  / 15)\n",
    "        if(len(data) != expected):\n",
    "            return False, \"esperado {} registros, encontrado {}\".format(expected, len(data))\n",
    "        else:\n",
    "            return True, \"OK\" \n",
    "    else:\n",
    "        return False, \"init: {} end:{} incorretos\".format(init, end)\n",
    "\n",
    "def __write_log__(status, message, file_name):\n",
    "    if(status):\n",
    "        with open(configs.correct_files,'a+') as resultFile:\n",
    "            resultFile.write(file_name+\"\\n\")\n",
    "    else:\n",
    "        with open(configs.error_files,'a+') as resultFile:\n",
    "            resultFile.write(file_name+\" \" + message+ \"\\n\")\n",
    "    \n",
    "def process_file(file_name, dt=datetime.timedelta(seconds=15)):\n",
    "    data = None\n",
    "    with open(file_name, 'r', encoding='utf-8') as infile:\n",
    "        data = infile.readlines()\n",
    "        try:\n",
    "            result, header = process_file_data(data, 0, dt)\n",
    "        \n",
    "            fstatus, fmessage =  audit_processed_file(result)\n",
    "            __write_log__(fstatus, fmessage, file_name)\n",
    "            if(not fstatus):\n",
    "                print(file_name, 'problem', fmessage)\n",
    "                return\n",
    "\n",
    "            result_file_name = configs.csv_dir + file_name.split('/')[-1]+'.csv'\n",
    "            with open(result_file_name,'w+') as resultFile:\n",
    "                wr = csv.writer(resultFile, dialect='excel')\n",
    "\n",
    "                wr.writerow(['time'] + header.split())\n",
    "                for row in result:\n",
    "                    wr.writerow(row)\n",
    "            print(result_file_name, ' escrito')\n",
    "        except InputError as error:\n",
    "            __write_log__(False, 'problemas no arquivo ~ {}'.format(error.message), file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_files_from_server():\n",
    "    ssh_client = paramiko.SSHClient()\n",
    "    ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh_client.connect(hostname=configs.hostname,\n",
    "                       username=configs.username,\n",
    "                       password=configs.password)\n",
    "    ftp_client=ssh_client.open_sftp()\n",
    "\n",
    "    # get list of files from server\n",
    "    server_file_list = ftp_client.listdir(configs.remote_dir)    \n",
    "    # compare to downloaded list of files\n",
    "    with open(configs.downloaded_files, 'r', encoding='utf-8') as infile:\n",
    "        downloaded_list = infile.readlines()\n",
    "\n",
    "    files_to_download = set(server_file_list).difference(set([x.strip() for x in downloaded_list]))\n",
    "    print(\"{} novos arquivos encontrados no servidor\".format(len(files_to_download)))\n",
    "    if(len(files_to_download) == 0):\n",
    "        return\n",
    "    \n",
    "    # download files needed\n",
    "    utils.download_files(ftp_client, configs.remote_dir, \n",
    "                         configs.original_DIR, files_to_download)\n",
    "    print(\"novos arquivos baixados\")\n",
    "    print(\"extraindo arquivos baixados\")\n",
    "    utils.extract_files(configs.original_DIR, \n",
    "                        configs.extracted_DIR, \n",
    "                        files_to_download)\n",
    "        \n",
    "    with open(configs.downloaded_files,'a+') as resultFile:\n",
    "        for file in files_to_download:\n",
    "            resultFile.write(file+\"\\n\")\n",
    "    print(\"extração completa\")\n",
    "        \n",
    "def process_files():\n",
    "    # get list of downloaded files\n",
    "    with open(configs.downloaded_files, 'r', encoding='utf-8') as infile:\n",
    "        downloaded_list = infile.readlines()\n",
    "    downloaded_list = [x.strip().replace('.tar.bz','') for x in downloaded_list]\n",
    "    # get list of processed files\n",
    "    with open(configs.processed_files, 'r', encoding='utf-8') as infile:\n",
    "        processed_list = infile.readlines()\n",
    "    processed_list = [x.strip() for x in processed_list]\n",
    "    \n",
    "    files_to_process = set(downloaded_list).difference(set(processed_list))\n",
    "    print(\"{} novos arquivos para processar\".format(len(files_to_process)))\n",
    "    if(len(files_to_process) == 0):\n",
    "        return\n",
    "\n",
    "    processed_files = open(configs.processed_files, 'a+', encoding='utf-8')\n",
    "    for file in files_to_process:\n",
    "        print('processing', file)\n",
    "        process_file(configs.extracted_DIR + file)\n",
    "        processed_files.write(file+\"\\n\")\n",
    "    processed_files.close()\n",
    "    print(\"novos arquivos processados\")\n",
    "    \n",
    "def import_files_db():\n",
    "    #\n",
    "    \n",
    "    None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 novos arquivos encontrados no servidor\n"
     ]
    }
   ],
   "source": [
    "print(\"fase 01\")\n",
    "download_files_from_server()\n",
    "process_files()\n",
    "print(\"fase 01 completa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
